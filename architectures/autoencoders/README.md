# Автоэнкодеры (Autoencoders)

## Описание

Автоэнкодеры - это тип нейронных сетей, предназначенных для не监督ого обучения эффективных кодирований входных данных. Они состоят из двух частей: энкодера, который сжимает входные данные в компактное представление (латентное пространство), и декодера, который восстанавливает исходные данные из этого представления.

## Архитектура

### Основные компоненты:
1. **Энкодер** - сжимает входные данные в латентное представление
2. **Латентное пространство** - компактное представление данных
3. **Декодер** - восстанавливает данные из латентного представления

### Основное свойство:
- Размер латентного пространства обычно меньше размера входных данных
- Сеть учится сохранять наиболее важную информацию при сжатии

## Типы автоэнкодеров

### 1. Простые автоэнкодеры
- Базовая архитектура с полносвязными слоями
- Используются для снижения размерности

### 2. Шумоподавляющие автоэнкодеры (Denoising Autoencoders)
- Обучаются восстанавливать "чистые" данные из "зашумленных" входов
- Повышают устойчивость к шуму

### 3. Разреженные автоэнкодеры (Sparse Autoencoders)
- Используют разреженные представления в латентном пространстве
- Активируют только небольшое количество нейронов

### 4. Вариационные автоэнкодеры (VAE)
- Вероятностный подход к автоэнкодерам
- Латентное пространство имеет вероятностное распределение
- Могут генерировать новые данные

## Преимущества

1. **Не监督ое обучение** - не требуют меток
2. **Снижение размерности** - эффективное сжатие данных
3. **Извлечение признаков** - автоматическое выделение важных характеристик
4. **Удаление шума** - могут очищать данные от шума
5. **Генерация данных** - особенно VAE могут создавать новые примеры

## Ограничения

1. **Потеря информации** - при сжатии часть информации теряется
2. **Сложность обучения** - могут быть нестабильными при обучении
3. **Ограниченная генерация** - качество сгенерированных данных может быть низким
4. **Интерпретируемость** - сложно интерпретировать латентное пространство

## Пример применения

В примере `autoencoder_example.py` показана реализация простого автоэнкодера для работы с изображениями MNIST. Сеть сжимает изображения 28x28 пикселей в 64-мерное латентное пространство, а затем восстанавливает их. Это демонстрирует возможности автоэнкодера по снижению размерности и восстановлению данных.

### Схематичное представление архитектуры:

| Входной слой | Энкодер (слой 1) | Энкодер (слой 2) | Энкодер (слой 3) | Латентное пространство | Декодер (слой 1) | Декодер (слой 2) | Декодер (слой 3) | Выходной слой |
|--------------|------------------|------------------|------------------|------------------------|------------------|------------------|------------------|---------------|
| 28×28 пикселей (784) | Linear: 784→256 | Linear: 256→128 | Linear: 128→64 | 64 нейрона | Linear: 64→128 | Linear: 128→256 | Linear: 256→784 | 28×28 пикселей |
|              | ReLU             | ReLU             | ReLU             |                       | ReLU             | ReLU             | ReLU             | Sigmoid       |

**Описание этапов:**
1. **Входной слой** - изображение MNIST размером 28×28 пикселей, преобразованное в вектор размерности 784
2. **Энкодер (слой 1)** - первый слой сжатия: 784 нейронов → 256 нейронов с ReLU активацией
3. **Энкодер (слой 2)** - второй слой сжатия: 256 нейронов → 128 нейронов с ReLU активацией
4. **Энкодер (слой 3)** - третий слой сжатия: 128 нейронов → 64 нейрона с ReLU активацией (латентное пространство)
5. **Латентное пространство** - компактное 64-мерное представление исходного изображения
6. **Декодер (слой 1)** - первый слой восстановления: 64 нейрона → 128 нейронов с ReLU активацией
7. **Декодер (слой 2)** - второй слой восстановления: 128 нейронов → 256 нейронов с ReLU активацией
8. **Декодер (слой 3)** - третий слой восстановления: 256 нейронов → 784 нейрона с ReLU активацией
9. **Выходной слой** - восстановленное изображение размером 28×28 пикселей с Sigmoid активацией для значений в диапазоне [0,1]

## Когда использовать автоэнкодеры?

Автоэнкодеры подходят для задач:
- Снижение размерности данных
- Удаление шума из данных
- Извлечение признаков
- Аномалия детекция
- Предварительное обучение для других задач
- Генерация новых данных (с VAE)

## Известные применения

- **Поиск аномалий** - обученный автоэнкодер хорошо восстанавливает нормальные данные, но хуже - аномальные
- **Рекомендательные системы** - для сжатия пользовательских предпочтений
- **Медицинская диагностика** - для выявления отклонений от нормы
- **Сжатие данных** - для эффективного хранения информации

## Современные альтернативы

Хотя автоэнкодеры остаются популярными, современные подходы включают:
- **VAE и их варианты** - для генерации данных
- **GAN** - для более качественной генерации
- **Трансформеры** - для работы с последовательностями