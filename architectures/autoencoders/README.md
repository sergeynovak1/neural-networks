# Автоэнкодеры (Autoencoders)

## Описание

Автоэнкодеры - это тип нейронных сетей, предназначенных для не监督ого обучения эффективных кодирований входных данных. Они состоят из двух частей: энкодера, который сжимает входные данные в компактное представление (латентное пространство), и декодера, который восстанавливает исходные данные из этого представления.

## Архитектура

### Основные компоненты:
1. **Энкодер** - сжимает входные данные в латентное представление
2. **Латентное пространство** - компактное представление данных
3. **Декодер** - восстанавливает данные из латентного представления

### Основное свойство:
- Размер латентного пространства обычно меньше размера входных данных
- Сеть учится сохранять наиболее важную информацию при сжатии

## Типы автоэнкодеров

### 1. Простые автоэнкодеры
- Базовая архитектура с полносвязными слоями
- Используются для снижения размерности

### 2. Шумоподавляющие автоэнкодеры (Denoising Autoencoders)
- Обучаются восстанавливать "чистые" данные из "зашумленных" входов
- Повышают устойчивость к шуму

### 3. Разреженные автоэнкодеры (Sparse Autoencoders)
- Используют разреженные представления в латентном пространстве
- Активируют только небольшое количество нейронов

### 4. Вариационные автоэнкодеры (VAE)
- Вероятностный подход к автоэнкодерам - ключевое отличие от обычных автоэнкодеров
- Латентное пространство имеет вероятностное распределение (обычно нормальное распределение) вместо фиксированной точки. Энкодер выводит не одно значение, а параметры распределения (среднее μ и дисперсию σ), из которого затем сэмплируется латентный вектор z
- Могут генерировать новые данные путем сэмплирования из латентного пространства, что делает генерацию более плавной и стабильной

**Разница между обычными автоэнкодерами и VAE:**
- **Обычный автоэнкодер** кодирует данные в фиксированную точку в латентном пространстве (детерминистическое кодирование). Хорошо работает для сжатия и восстановления данных, но генерация новых примеров может быть нестабильной, так как латентное пространство может иметь "дыры" (непрерывные области, не соответствующие реальным данным)
- **VAE** кодирует данные в вероятностное распределение, что делает латентное пространство более "гладким" и непрерывным. Это позволяет генерировать новые примеры путем случайного сэмплирования из латентного пространства, при этом сгенерированные примеры будут похожи на обучающие данные. VAE также включает регуляризацию (KL divergence loss), которая заставляет латентное распределение быть близким к стандартному нормальному распределению, что дополнительно структурирует латентное пространство

## Преимущества

1. **Не监督ое обучение** - не требуют меток
2. **Снижение размерности** - эффективное сжатие данных
3. **Извлечение признаков** - автоматическое выделение важных характеристик
4. **Удаление шума** - могут очищать данные от шума
5. **Генерация данных** - особенно VAE могут создавать новые примеры

## Ограничения

1. **Потеря информации** - при сжатии часть информации теряется
2. **Сложность обучения** - могут быть нестабильными при обучении
3. **Ограниченная генерация** - качество сгенерированных данных может быть низким
4. **Интерпретируемость** - сложно интерпретировать латентное пространство

## Пример применения

В примере `autoencoder_example.py` показана реализация простого автоэнкодера для работы с изображениями MNIST. Сеть сжимает изображения 28x28 пикселей в 64-мерное латентное пространство, а затем восстанавливает их. Это демонстрирует возможности автоэнкодера по снижению размерности и восстановлению данных.

## Разбор примера из autoencoder_example.py

Разберем, как работает код на примере сжатия изображений MNIST:

### Архитектура (строки 16-48)

Автоэнкодер состоит из двух частей:

**1. Энкодер (строки 21-28) - сжатие:**
```python
# Вход: изображение 28×28 = 784 пикселя
# Linear(784→256) → ReLU → Linear(256→128) → ReLU → Linear(128→64)
# Выход: латентный вектор размерности 64 (сжатие в 12 раз!)
```

**2. Декодер (строки 31-38) - восстановление:**
```python
# Вход: латентный вектор размерности 64
# Linear(64→128) → ReLU → Linear(128→256) → ReLU → Linear(256→784) → Sigmoid
# Выход: восстановленное изображение 28×28
```

### Процесс работы (строки 40-43)

```python
def forward(self, x):
    encoded = self.encoder(x)      # Сжатие: 784 → 64
    decoded = self.decoder(encoded) # Восстановление: 64 → 784
    return decoded
```

**Пример:**
- Вход: изображение цифры "5" (784 пикселя)
- Энкодер: сжимает до 64 чисел, сохраняя ключевые признаки формы
- Декодер: восстанавливает изображение "5" из этих 64 чисел
- Функция потерь (MSE, строка 70): сравнивает оригинал и восстановленное изображение

### Обучение (строки 50-92)

- Цель: минимизировать разницу между оригинальным и восстановленным изображением
- Результат: сеть учится сохранять важную информацию при сжатии
- Применение: можно использовать энкодер для снижения размерности других данных (строка 126)

### Схематичное представление архитектуры:

| Входной слой | Энкодер (слой 1) | Энкодер (слой 2) | Энкодер (слой 3) | Латентное пространство | Декодер (слой 1) | Декодер (слой 2) | Декодер (слой 3) | Выходной слой |
|--------------|------------------|------------------|------------------|------------------------|------------------|------------------|------------------|---------------|
| 28×28 пикселей (784) | Linear: 784→256 | Linear: 256→128 | Linear: 128→64 | 64 нейрона | Linear: 64→128 | Linear: 128→256 | Linear: 256→784 | 28×28 пикселей |
|              | ReLU             | ReLU             | ReLU             |                       | ReLU             | ReLU             | ReLU             | Sigmoid       |

**Описание этапов:**
1. **Входной слой** - изображение MNIST размером 28×28 пикселей, преобразованное в вектор размерности 784
2. **Энкодер (слой 1)** - первый слой сжатия: 784 нейронов → 256 нейронов с ReLU активацией
3. **Энкодер (слой 2)** - второй слой сжатия: 256 нейронов → 128 нейронов с ReLU активацией
4. **Энкодер (слой 3)** - третий слой сжатия: 128 нейронов → 64 нейрона с ReLU активацией (латентное пространство)
5. **Латентное пространство** - компактное 64-мерное представление исходного изображения
6. **Декодер (слой 1)** - первый слой восстановления: 64 нейрона → 128 нейронов с ReLU активацией
7. **Декодер (слой 2)** - второй слой восстановления: 128 нейронов → 256 нейронов с ReLU активацией
8. **Декодер (слой 3)** - третий слой восстановления: 256 нейронов → 784 нейрона с ReLU активацией
9. **Выходной слой** - восстановленное изображение размером 28×28 пикселей с Sigmoid активацией для значений в диапазоне [0,1]

## Когда использовать автоэнкодеры?

Автоэнкодеры подходят для задач:
- Снижение размерности данных
- Удаление шума из данных
- Извлечение признаков
- Аномалия детекция
- Предварительное обучение для других задач
- Генерация новых данных (с VAE)

## Известные применения

- **Поиск аномалий** - обученный автоэнкодер хорошо восстанавливает нормальные данные, но хуже - аномальные
- **Рекомендательные системы** - для сжатия пользовательских предпочтений
- **Медицинская диагностика** - для выявления отклонений от нормы
- **Сжатие данных** - для эффективного хранения информации

## Современные альтернативы

Хотя автоэнкодеры остаются популярными, современные подходы включают:
- **VAE и их варианты** - для генерации данных
- **GAN** - для более качественной генерации
- **Трансформеры** - для работы с последовательностями