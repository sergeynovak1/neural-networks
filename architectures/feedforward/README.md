# Фидфорвардные сети (Feedforward Networks)

## Описание

Фидфорвардные сети (Feedforward Networks) - это самый простой тип нейронных сетей, где информация движется только в одном направлении - от входного слоя через скрытые слои к выходному слою, без циклов или обратных связей. Это основа для всех других типов нейронных сетей.

## История

Фидфорвардные сети имеют долгую историю:
- **1943** - Модель McCulloch-Pitts (первые математические нейроны)
- **1958** - Перцептрон Розенблатта
- **1986** - Алгоритм обратного распространения ошибки (backpropagation)
- **2006** - Глубокое обучение (Deep Learning)

## Архитектура

### Основные компоненты:
1. **Входной слой** - получает данные
2. **Скрытые слои** - выполняют вычисления и извлекают признаки
3. **Выходной слой** - выдает результат

### Типы фидфорвардных сетей:
- **Перцептрон** - один нейрон
- **Многослойный перцептрон (MLP)** - несколько скрытых слоев
- **Радиально-базисные функциональные сети** - используют радиальные базисные функции

## Преимущества

1. **Простота** - легко понять и реализовать
2. **Универсальность** - могут аппроксимировать любую непрерывную функцию (Universal Approximation Theorem)
3. **Параллелизм** - все нейроны в слое могут вычисляться параллельно
4. **Стабильность** - нет проблем с циклами и обратными связями

## Ограничения

1. **Не подходят для последовательностных данных** - не имеют внутренней памяти
2. **Проблемы с глубокими сетями** - исчезающий градиент при обучении
3. **Не эффективны для структурированных данных** - плохо работают с изображениями, звуком без модификаций
4. **Черный ящик** - сложно интерпретировать внутренние представления

## Пример применения

В примере `feedforward_example.py` показана реализация многослойного перцептрона (MLP) для задачи многоклассовой классификации. Сеть состоит из входного слоя, двух скрытых слоев с ReLU активацией и Dropout регуляризацией, и выходного слоя с Softmax активацией для классификации.

## Когда использовать фидфорвардные сети?

Фидфорвардные сети подходят для задач:
- Классификация и регрессия с табличными данными
- Приближение математических функций
- Задачи с фиксированным размером входных данных
- В качестве компонента в более сложных архитектурах

## Известные архитектуры

- **Перцептрон Розенблатта** - первый алгоритм обучения нейронной сети
- **LeNet-5** - ранняя CNN, но основана на фидфорвардной архитектуре
- **MLP** - стандартный многослойный перцептрон

## Схематичное представление архитектуры MLP

На основе примера `feedforward_example.py`, ниже представлена упрощенная схема многослойного перцептрона (MLP) в виде таблицы:

| Входной слой | Скрытый слой 1 | Скрытый слой 2 | Выходной слой |
|--------------|----------------|----------------|---------------|
| 20 нейронов  | 64 нейрона     | 32 нейрона     | 3 нейрона     |
| Входные признаки | ReLU        | ReLU           | Softmax       |
|              | Dropout        | Dropout        | 3 класса      |

Более подробная архитектура сети:
- Входной слой: 20 нейронов (соответствует количеству признаков входных данных)
- Скрытый слой 1: 64 нейрона с ReLU активацией и Dropout (20%)
- Скрытый слой 2: 32 нейрона с ReLU активацией и Dropout (20%)
- Выходной слой: 3 нейрона с Softmax активацией (соответствует количеству классов)

## Современное применение

Хотя фидфорвардные сети не являются передовым решением для многих задач, они остаются важными:
- В составе более сложных архитектур (например, в конце CNN)
- Для задач с табличными данными
- Как базовые модели для сравнения