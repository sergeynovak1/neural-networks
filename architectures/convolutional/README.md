# Сверточные нейронные сети (CNN)

## Описание

Сверточные нейронные сети (Convolutional Neural Networks, CNN) - это класс глубоких нейронных сетей, наиболее успешно применяемых для анализа визуальных образов. Они используются в таких задачах, как распознавание образов и классификация изображений, обнаружение объектов и сегментация.

## Основные компоненты

### 1. Сверточные слои (Convolutional Layers)
- Применяют фильтры (ядра) к входным данным - небольшие матрицы весов (например, 3×3 или 5×5), которые "скользят" по изображению
- Извлекают локальные признаки из изображений - каждый фильтр специализируется на поиске определенного типа признака (края, углы, текстуры)
- Позволяют сети автоматически учиться распознавать визуальные паттерны без ручного выделения признаков

### 2. Слои объединения (Pooling Layers)
- Уменьшают пространственные размеры представления
- Помогают сделать представление инвариантным к небольшим изменениям положения
- Наиболее распространенный тип - Max Pooling

### 3. Полносвязные слои (Fully Connected Layers)
- Обычно находятся в конце сети
- Используются для окончательной классификации
- Соединяют все признаки в единое решение

### Схематичное представление архитектуры:

| Входное изображение | Сверточный слой 1 | Pooling слой 1 | Сверточный слой 2 | Pooling слой 2 | Сверточный слой 3 | Pooling слой 3 | Полносвязные слои | Выходной слой |
|---------------------|-------------------|----------------|-------------------|----------------|-------------------|----------------|-------------------|---------------|
| 3 канала (RGB)      | Conv2d: 3→32      | MaxPool2d: 2×2 | Conv2d: 32→64     | MaxPool2d: 2×2 | Conv2d: 64→128    | MaxPool2d: 2×2 | Linear: 2048→512  | Linear: 512→10|
| 32×32 пикселей      | Kernel: 3×3       |                | Kernel: 3×3       |                | Kernel: 3×3       |                | ReLU              | 10 классов    |
|                     | ReLU              |                | ReLU              |                | ReLU              |                | Dropout: 0.5      |               |

**Описание этапов:**
1. **Входное изображение** - изображения формата CIFAR-10 размером 32×32 пикселя с 3 цветными каналами (RGB)
2. **Сверточный слой 1** - извлекает базовые признаки (края, углы) с помощью 32 фильтров размером 3×3
3. **Pooling слой 1** - уменьшает размерность признаков в 2 раза с помощью MaxPooling
4. **Сверточный слой 2** - извлекает более сложные признаки с помощью 64 фильтров размером 3×3
5. **Pooling слой 2** - уменьшает размерность признаков в 2 раза с помощью MaxPooling
6. **Сверточный слой 3** - извлекает высокоуровневые признаки с помощью 128 фильтров размером 3×3
7. **Pooling слой 3** - уменьшает размерность признаков в 2 раза с помощью MaxPooling
8. **Полносвязные слои** - комбинируют все извлеченные признаки для классификации, преобразуя 2048 признаков в 512, затем применяют регуляризацию Dropout
9. **Выходной слой** - окончательная классификация на 10 классов набора данных CIFAR-10

## Преимущества CNN

1. **Параметрическая связь** - один и тот же набор весов (фильтр) применяется ко всем участкам изображения, что позволяет находить одинаковые признаки (например, горизонтальные края, углы, текстуры) в любом месте изображения. Вместо того, чтобы учить отдельные веса для каждой позиции пикселя, CNN использует небольшое ядро (обычно 3×3 или 5×5), которое "скользит" по изображению. Это значительно экономит параметры: для изображения 224×224 полносвязный слой имел бы миллионы параметров, CNN же использует тысячи параметров на фильтр

2. **Иерархическое извлечение признаков** - более сложные признаки строятся на основе простых. Первые слои находят простые паттерны (края, линии, углы), средние слои комбинируют их в более сложные структуры (геометрические формы, части объектов), а глубокие слои распознают целые объекты или сцены

3. **Инвариантность к сдвигу** - сеть может распознавать объект независимо от его положения на изображении (например, кошку в левом верхнем углу или в правом нижнем). Это достигается за счет двух механизмов: (1) применение одинаковых фильтров по всему изображению позволяет найти признак в любой позиции, (2) операции объединения (pooling) уменьшают чувствительность к точному положению признака, сохраняя его наличие

4. **Экономия параметров** - значительно меньше параметров по сравнению с полносвязными сетями. Например, для обработки изображения 224×224 с 3 каналами: полносвязный слой потребовал бы 150,528×N параметров (где N - число нейронов), в то время как сверточный слой с 64 фильтрами 3×3 имеет всего 64×3×3×3 = 1,728 параметров

## Пример применения

В примере `cnn_example.py` показана реализация простой CNN для классификации изображений CIFAR-10. Сеть состоит из трех сверточных блоков с ReLU активацией и MaxPooling, за которыми следуют полносвязные слои для классификации.

## Разбор примера из cnn_example.py

Разберем, как работает код на примере классификации изображений CIFAR-10:

### Архитектура модели (строки 14-46)

Класс `SimpleCNN` состоит из двух частей:

**1. Feature extraction (строки 17-32)** - извлечение признаков:
```python
# Вход: изображение (batch, 3, 32, 32) - CIFAR-10 имеет размер 32×32×3

# Блок 1: Conv2d(3→32, kernel=3, padding=1) → ReLU → MaxPool2d(2)
#  32×32×3 → 32×32×32 → 16×16×32

# Блок 2: Conv2d(32→64, kernel=3, padding=1) → ReLU → MaxPool2d(2)  
#  16×16×32 → 16×16×64 → 8×8×64

# Блок 3: Conv2d(64→128, kernel=3, padding=1) → ReLU → MaxPool2d(2)
#  8×8×64 → 8×8×128 → 4×4×128
```

**2. Classifier (строки 35-40)** - классификация:
```python
# Flatten: 4×4×128 = 2048 признаков
# Linear(2048→512) → ReLU → Dropout(0.5) → Linear(512→10)
# Выход: 10 классов CIFAR-10
```

### Процесс обучения (строки 49-109)

1. **Подготовка данных** (строки 51-68): загружается CIFAR-10, применяются трансформации (нормализация, аугментация)
2. **Forward pass** (строки 87-88): изображение проходит через все слои, на выходе - логиты для 10 классов
3. **Loss и оптимизация** (строки 88-90): CrossEntropyLoss вычисляет ошибку, Adam обновляет веса
4. **Результат**: сеть учится классифицировать изображения на 10 классов (самолет, автомобиль, птица, кошка и т.д.)

## Когда использовать CNN?

CNN идеально подходят для задач:
- Классификация изображений
- Обнаружение объектов
- Сегментация изображений
- Распознавание лиц
- Анализ медицинских изображений

## Известные архитектуры

- **LeNet** - одна из первых CNN, использовалась для распознавания рукописных цифр
- **AlexNet** - прорыв в ImageNet 2012, показала силу глубоких CNN
- **VGG** - глубокая архитектура с маленькими фильтрами 3x3
- **ResNet** - использует skip-соединения для обучения очень глубоких сетей
- **Inception/GoogLeNet** - применяет фильтры разных размеров параллельно